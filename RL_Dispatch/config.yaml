# case generation
base_grid: "packages/grid/14nodes/14nodes.json"
num_case: 100
obj2change: ["load"]
attr2change: ["p_mw"]
fluc_area: [[0.8, 1.2]]


# experiment
total_step: 10000
data_folder: "packages/data/14nodes"
# replay_buffer_size: 1000000
replay_buffer_size: 10000
# learning_starts: 50000
learning_starts: 500
learning_freq: 4
target_update_freq: 500
# log
log_every_n_steps: 500


# wrapper
reward_border: [0.94, 0.97, 1.03, 1.06]
reward_value: [-1, 0.5, 1]
diverge_border: [0.4, 2]

# action
num_actor: 4
actor: gen
action_attribute: vm_pu
action_enum: [0.95, 0.975, 1, 1.025, 1.05]

# observation
observer: [res_bus, res_bus, res_line, res_line]
observe_attribute: [vm_pu, va_degree, p_from_mw, q_from_mvar]
target: [res_bus]
target_attribute: [vm_pu]
# episode
max_step: 4


# schedule
schedule_type: linear
schedule_timesteps: 10000
final_p: 0.1

# learning rate
learning_rate: 0.005
step_optimizer: True
step_size: 5000
# learning rate衰减率
gamma_lr: 0.5

# Hyper parameter
# network
num_layer: 3
layer_size: [128, 64, 32]
# Deep learning training
batch_size: 32
# next Q衰减率
gamma: 0.99
alpha: 0.95
eps: 0.01


